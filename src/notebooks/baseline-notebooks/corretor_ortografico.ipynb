{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "from nlp.preprocessing import (\n",
    "    clean_text,\n",
    "    preprocess,\n",
    "    tokenize,\n",
    "    preprocess_document,\n",
    "    tokenize_document,\n",
    "    get_stopwords,\n",
    "    lemmatization)\n",
    "from nlp.text_statistics import (\n",
    "    number_tokens,\n",
    "    tokens_length,\n",
    "    unique_tokens,\n",
    "    count_numbers,\n",
    "    number_stopwords,\n",
    "    print_statistics,\n",
    "    count_tokens\n",
    ")\n",
    "from nlp.grouping import (\n",
    "    get_groups,\n",
    "    get_groups_size,\n",
    "    get_first_token_groups\n",
    ")\n",
    "from nlp.utils import (\n",
    "    read_dictionary\n",
    ")\n",
    "from nlp.spellcheckeropt import SpellcheckerOpt\n",
    "from gensim.parsing.preprocessing import (\n",
    "    strip_multiple_whitespaces,\n",
    "    strip_non_alphanum,\n",
    "    strip_punctuation2,\n",
    "    strip_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_recurso = '/Users/Pedro/Desktop/projeto-mp/dados/licitacao_vlr_recurso_funcao.csv'\n",
    "data_recurso = pd.read_csv(file_recurso, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_recurso.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "licitacoes_saude = data_recurso.loc[(data_recurso['nom_funcao'] == 'SaÃºde') & (data_recurso['proporcao_vlr'] >= 5.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dim_licitacao_list = list(licitacoes_saude['seq_dim_licitacao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(seq_dim_licitacao_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/Pedro/Desktop/projeto-mp/dados/itens_pregao_pitem_saude.csv'\n",
    "data = pd.read_csv(file, sep=';')\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['seq_dim_licitacao'].isin(seq_dim_licitacao_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(list(data['seq_dim_licitacao'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(data['nom_item'])\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_descriptions = preprocess(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(items_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_file = '/Users/Pedro/Desktop/projeto-mp/dados/palavras/words_nilc.txt'\n",
    "portuguese_words, all_words_nilc = read_dictionary(words_file, preprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_nilc = list(set(all_words_nilc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/Pedro/Desktop/projeto-mp/dados/palavras/words_nilc_preprocessed.json\", \"w\") as JFile:\n",
    "    json.dump(all_words_nilc, JFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter, words_list in portuguese_words.items():\n",
    "    print(letter, ':', len(words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(portuguese_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell2 = SpellChecker(language='en', case_sensitive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = unique_tokens(items_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = collections.defaultdict(list)\n",
    "\n",
    "for token in unique:\n",
    "    unique_words[token[0]].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for letter, words_list in unique_words.items():\n",
    "    print(letter, ':', len(words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = open('/Users/Pedro/Desktop/projeto-mp/dados/palavras/words_nilc_preprocess.txt', \"r\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = list(set(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ccomcex\\n',\n",
       " 'paroxistica\\n',\n",
       " 'arreganhar\\n',\n",
       " 'interrogativo\\n',\n",
       " 'pulmonar\\n',\n",
       " 'versas\\n',\n",
       " 'cancele\\n',\n",
       " 'dumaine\\n',\n",
       " 'papando\\n',\n",
       " 'smart\\n']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_nilc = list(set(all_words_nilc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_words_nilc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tokens = get_first_token_groups(items_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tokens_groups = get_groups(first_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(first_tokens_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spellchecker = SpellcheckerOpt()\n",
    "spellchecker.load_words(list(first_tokens_groups.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_words = {}\n",
    "i = 0\n",
    "\n",
    "for group, count in first_tokens_groups.items():\n",
    "    groups_words[group] = spellchecker.search(group, 2)\n",
    "    i += 1\n",
    "    if i%1000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "list_words_sizes = []\n",
    "\n",
    "for group, words_list in groups_words.items():\n",
    "    words_list.sort(key=lambda x:(x[1],x[0]))\n",
    "    list_words_sizes.append(len(words_list))\n",
    "    if len(words_list) > 1:\n",
    "        count += 1\n",
    "    print(group, ':', words_list)\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for group, list_words in groups_words.items():\n",
    "    if len(list_words) > 1:\n",
    "        count += 1\n",
    "        \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for group, list_words in groups_words.items():\n",
    "    if first_tokens_groups[group] == 1:\n",
    "        if len(list_words) > 1:\n",
    "            count += 1\n",
    "        \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics(list_words_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups = collections.defaultdict(int)\n",
    "\n",
    "for group, words_list in groups_words.items():\n",
    "    \n",
    "    maxi = 1\n",
    "    op = group\n",
    "    for word in words_list:\n",
    "        if word[1] > maxi:\n",
    "            maxi = word[1]\n",
    "            op = word[0]\n",
    "\n",
    "    new_groups[op] += first_tokens_groups[op]\n",
    "    first_tokens_groups[op] = 0\n",
    "    new_groups[op] += first_tokens_groups[group]\n",
    "    first_tokens_groups[group] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups_sizes = get_groups_size(new_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups_sizes.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spellchecker = SpellcheckerOpt()\n",
    "spellchecker.load_words(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "search_words = {}\n",
    "i = 0\n",
    "\n",
    "for word in unique[:100]:\n",
    "    search_words[word] = spellchecker.search(word, 2)\n",
    "    i += 1\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, words_list in search_words.item():\n",
    "    print(word, ':', words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups2 = collections.defaultdict(int)\n",
    "\n",
    "for group, words_list in groups_words.items():\n",
    "    if first_tokens_groups[group] == 1: \n",
    "        new_groups2[group] += first_tokens_groups[group]\n",
    "        first_tokens_groups[group] = 0\n",
    "        for word in words_list:\n",
    "            new_groups2[group] += first_tokens_groups[word[0]]\n",
    "            first_tokens_groups[word[0]] = 0\n",
    "    else:\n",
    "        new_groups2[group] += first_tokens_groups[group]\n",
    "        first_tokens_groups[group] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups3 = collections.defaultdict(int)\n",
    "count = 0\n",
    "\n",
    "for group, size in new_groups2.items():\n",
    "    if size == 0:\n",
    "        count += 1\n",
    "    else:\n",
    "        new_groups3[group] = size\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_groups3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for group, size in new_groups3.items():\n",
    "    if size == 1:\n",
    "        count += 1\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for group, size in first_tokens_groups.items():\n",
    "    if size >= 1:\n",
    "        count += 1\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
