{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import copy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from nlp.preprocessing import (\n",
    "    clean_text,\n",
    "    preprocess,\n",
    "    tokenize,\n",
    "    preprocess_document,\n",
    "    tokenize_document,\n",
    "    get_stopwords, \n",
    "    lemmatization_document,\n",
    "    get_canonical_words)\n",
    "from nlp.utils import (\n",
    "    plot_histogram,\n",
    "    get_completetext,\n",
    "    plot_wordcloud,\n",
    "    print_statistics,\n",
    "    groups_frequency_sort)\n",
    "from nlp.text_statistics import (\n",
    "    count_tokens,\n",
    "    unique_tokens,\n",
    "    sort_frequency_tokens\n",
    ")\n",
    "from nlp.grouping import (\n",
    "    get_groups,\n",
    "    get_groups_size,\n",
    "    get_unigram_groups,\n",
    "    get_two_tokens_groups,\n",
    "    get_first_token_groups,\n",
    "    get_bigram_groups,\n",
    "    get_first_two_groups,\n",
    "    groups_frequency_sort\n",
    ")\n",
    "from utils.read_files import (\n",
    "    get_items)\n",
    "from item.item_list import (\n",
    "    ItemList,\n",
    "    Item\n",
    ")\n",
    "from item.spellcheckeropt import SpellcheckerOpt\n",
    "from item.utils import get_tokens_set\n",
    "from textpp_ptbr.preprocessing import TextPreProcessing as tpp\n",
    "from gensim.parsing.preprocessing import (\n",
    "    strip_multiple_whitespaces,\n",
    "    strip_non_alphanum,\n",
    "    strip_punctuation2,\n",
    "    strip_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "medicamentos_file = pd.read_csv('../dados/medicamentos.csv', delimiter='_', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "medicamentos_file.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "substancias = list(medicamentos_file['SUBSTÂNCIA'])\n",
    "produtos = list(medicamentos_file['PRODUTO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "medicamentos_set = set()\n",
    "stopwords_ = get_stopwords()\n",
    "medicamentos_list = substancias + produtos\n",
    "\n",
    "for med in medicamentos_list:\n",
    "    doc = preprocess_document(med, remove_numbers=False)\n",
    "    doc = tokenize_document(doc, stopwords_)\n",
    "    print(doc)\n",
    "    for tok in doc:\n",
    "        medicamentos_set.add(tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(medicamentos_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count = 0\n",
    "for med in medicamentos_set:\n",
    "    if len(med) >= 0:\n",
    "        count += 1\n",
    "        print(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemlist = ItemList()\n",
    "itemlist.load_items_from_file('../dados/items_preprocessed.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicamentos = get_tokens_set('../dados/palavras/medications.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_form, word_class = get_canonical_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = set()\n",
    "\n",
    "for token, tag in word_class.items():\n",
    "    tags.add(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_list = itemlist.items_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_words = []\n",
    "\n",
    "for item in items_list:\n",
    "    item_dict = item.get_item_dict()\n",
    "    items_words.append(item_dict['palavras'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for doc in items_words:\n",
    "    count += len(doc)\n",
    "    \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tags = []\n",
    "not_tagged = 0\n",
    "tag_count = collections.defaultdict(int)\n",
    "\n",
    "for doc in items_words:\n",
    "    for tok in doc:\n",
    "        if tok in word_class:\n",
    "            word_tags.append((tok, word_class[tok]))\n",
    "            tag_count[word_class[tok]] += 1\n",
    "        elif tok in medicamentos:\n",
    "            word_tags.append((tok, 'MED'))\n",
    "            tag_count['MED'] += 1\n",
    "        else:\n",
    "            word_tags.append((tok, 'UNTAGGED'))\n",
    "            not_tagged += 1\n",
    "            \n",
    "not_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for doc in items_words:\n",
    "    for tok in doc:\n",
    "        if tok in word_class and word_class[tok] == 'N':\n",
    "            count += 1\n",
    "            break\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(items_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_name_count = sort_frequency_tokens(tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_name_count[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(word_tags, columns=['word', 'tag'])\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "fig, (axis1) = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.countplot(y=\"tag\", data=dataframe, color='dodgerblue', order=dataframe['tag'].value_counts().index)\n",
    "\n",
    "axis1.set_xlabel(\"Nº de tokens\", fontsize=20, weight='bold')\n",
    "axis1.set_ylabel(\"Tag\", fontsize=20, weight='bold')\n",
    "plt.grid(False)\n",
    "plt.xscale('log')\n",
    "\n",
    "total = len(dataframe)\n",
    "for p in axis1.patches:\n",
    "    width = p.get_width()\n",
    "    axis1.text(width, p.get_y()+0.5, '%.2f%%'%(100*float(width)/total), fontsize=15)\n",
    "\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "\n",
    "for doc in items_words:\n",
    "    for tok in doc:\n",
    "        words.append(tok)\n",
    "        \n",
    "words = list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_word_tags = []\n",
    "not_tagged = 0\n",
    "\n",
    "for tok in words:\n",
    "    if tok in word_class:\n",
    "        unique_word_tags.append((tok, word_class[tok]))\n",
    "    elif tok in medicamentos:\n",
    "        unique_word_tags.append((tok, 'MED'))\n",
    "    else:\n",
    "        unique_word_tags.append((tok, 'UNTAGGED'))\n",
    "        not_tagged += 1\n",
    "        \n",
    "not_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_word_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(unique_word_tags, columns=['word', 'tag'])\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "fig, (axis1) = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.countplot(y=\"tag\", data=dataframe, color='dodgerblue', order=dataframe['tag'].value_counts().index)\n",
    "\n",
    "axis1.set_xlabel(\"Nº de tokens\", fontsize=20, weight='bold')\n",
    "axis1.set_ylabel(\"Tag\", fontsize=20, weight='bold')\n",
    "plt.grid(False)\n",
    "plt.xscale('log')\n",
    "\n",
    "total = len(dataframe)\n",
    "for p in axis1.patches:\n",
    "    width = p.get_width()\n",
    "    axis1.text(width, p.get_y()+0.5, '%.2f%%'%(100*float(width)/total), fontsize=15)\n",
    "\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_token_groups = itemlist.get_first_token_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = list(first_token_groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colagenase',\n",
       " 'campo',\n",
       " 'kit',\n",
       " 'tinta',\n",
       " 'termometro',\n",
       " 'diclofenaco',\n",
       " 'panfleto',\n",
       " 'bota',\n",
       " 'ciprofloxacino',\n",
       " 'dea']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18035"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstt_groups_size = itemlist.get_groups_size(first_token_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, items in first_token_groups.items():\n",
    "    first_token_groups[group] = len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6337"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstt_groups_size.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstt_groups_size.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26250, 23035, 21414, 21261, 20958, 20285, 16153, 14528, 14484, 12557]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstt_groups_size[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstt_groups_names_size = groups_frequency_sort(first_token_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('papel', 26250),\n",
       " ('broca', 23035),\n",
       " ('pneu', 21414),\n",
       " ('luva', 21261),\n",
       " ('sonda', 20958),\n",
       " ('filtro', 20285),\n",
       " ('oleo', 16153),\n",
       " ('fita', 14528),\n",
       " ('tubo', 14484),\n",
       " ('fio', 12557)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstt_groups_names_size[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_size(size):\n",
    "\n",
    "    if size == 1:\n",
    "        interval = '1'\n",
    "    elif size > 1 and size <= 5:\n",
    "        interval = '(1,5]'\n",
    "    elif size > 5 and size <= 10:\n",
    "        interval = '(5,10]'\n",
    "    elif size > 10 and size <= 100:\n",
    "        interval = '(10,100]'\n",
    "    elif size > 100 and size <= 1000:\n",
    "        interval = '(100,1000]'\n",
    "    elif size > 1000 and size <= 5000:\n",
    "        interval = '(1000,5000]'\n",
    "    elif size > 5000 and size <= 10000:\n",
    "        interval = '(5000,10000]'\n",
    "    else:\n",
    "        interval = '>10000'\n",
    "\n",
    "    return interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11391"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_tags = []\n",
    "not_tagged = 0\n",
    "items_in_untagged = 0\n",
    "\n",
    "for group in groups:\n",
    "    if group in word_class:\n",
    "        group_tags.append((group, word_class[group], group_size(first_token_groups[group])))\n",
    "    elif group in medicamentos:\n",
    "        group_tags.append((group, 'MED', group_size(first_token_groups[group])))\n",
    "    else:\n",
    "        group_tags.append((group, 'UNTAGGED', group_size(first_token_groups[group])))\n",
    "        items_in_untagged += first_token_groups[group]\n",
    "        not_tagged += 1\n",
    "\n",
    "not_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116287"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_in_untagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1508992"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itemlist.items_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.706270145898719"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*(items_in_untagged/len(itemlist.items_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_tags_sample = []\n",
    "\n",
    "for word, tag, group_size in group_tags:\n",
    "    if tag in {'UNTAGGED', 'N', 'V', 'A', 'MED'}:\n",
    "        group_tags_sample.append((word, tag, group_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(group_tags, columns=['word', 'tag', 'group_size'])\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "fig, (axis1) = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.countplot(y=\"group_size\", hue=\"tag\", data=dataframe, order=dataframe['group_size'].value_counts().index)\n",
    "\n",
    "axis1.set_xlabel(\"Nº de tokens\", fontsize=20, weight='bold')\n",
    "axis1.set_ylabel(\"Tamanho do grupo\", fontsize=20, weight='bold')\n",
    "plt.grid(False)\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='lower right', title='Classe', fontsize='large', title_fontsize='x-large')\n",
    "\n",
    "# total = len(dataframe)\n",
    "# for p in axis1.patches:\n",
    "#     width = p.get_width()\n",
    "#     axis1.text(width, p.get_y()+0.5, '%.2f%%'%(100*float(width)/total), fontsize=15)\n",
    "\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "fig, (axis1) = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.countplot(y=\"tag\", data=dataframe, color='dodgerblue', order=dataframe['tag'].value_counts().index)\n",
    "\n",
    "axis1.set_xlabel(\"Nº de tokens\", fontsize=20, weight='bold')\n",
    "axis1.set_ylabel(\"Tag\", fontsize=20, weight='bold')\n",
    "plt.grid(False)\n",
    "plt.xscale('log')\n",
    "\n",
    "total = len(dataframe)\n",
    "for p in axis1.patches:\n",
    "    width = p.get_width()\n",
    "    axis1.text(width, p.get_y()+0.5, '%.2f%%'%(100*float(width)/total), fontsize=15)\n",
    "\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count = count_tokens(items_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_name_count = sort_frequency_tokens(token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1000_tokens = token_name_count[:1000]\n",
    "top1000_tokens = [tok for tok, count in top1000_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tags = []\n",
    "not_tagged = 0\n",
    "\n",
    "for token in top1000_tokens:\n",
    "    if token in word_class:\n",
    "        top_tags.append((token, word_class[token]))\n",
    "    elif token in medicamentos:\n",
    "        top_tags.append((token, 'MED'))\n",
    "    else:\n",
    "        top_tags.append((token, 'UNTAGGED'))\n",
    "        not_tagged += 1\n",
    "\n",
    "not_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(top_tags, columns=['word', 'tag'])\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "fig, (axis1) = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.countplot(y=\"tag\", data=dataframe, color='dodgerblue', order=dataframe['tag'].value_counts().index)\n",
    "\n",
    "axis1.set_xlabel(\"Nº de tokens\", fontsize=20, weight='bold')\n",
    "axis1.set_ylabel(\"Tag\", fontsize=20, weight='bold')\n",
    "plt.grid(False)\n",
    "plt.xscale('log')\n",
    "\n",
    "total = len(dataframe)\n",
    "for p in axis1.patches:\n",
    "    width = p.get_width()\n",
    "    axis1.text(width, p.get_y()+0.5, '%.2f%%'%(100*float(width)/total), fontsize=15)\n",
    "\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings_file = '/Users/Pedro/Desktop/projeto-mp/dados/word embeddings/glove_s50.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_embeddings(file):\n",
    "\n",
    "    word_embeddings = {}\n",
    "\n",
    "    with open(file, 'r') as data:\n",
    "\n",
    "        data.readline()\n",
    "        lines = data.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip('\\n')\n",
    "            line = line.split(' ', maxsplit=1)\n",
    "            token = line[0]\n",
    "            token_preprocess = tpp.remove_accents(token.lower())\n",
    "            embedding = line[1].split(' ')\n",
    "            embedding = [float(num) for num in embedding]\n",
    "            word_embeddings[token_preprocess] = embedding\n",
    "\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = load_word_embeddings(word_embeddings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_set = set(word_embeddings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_tags = []\n",
    "not_tagged = 0\n",
    "\n",
    "for token in words_set:\n",
    "    if token in word_class:\n",
    "        word_embedding_tags.append((token, word_class[token]))\n",
    "    elif token in medicamentos:\n",
    "        word_embedding_tags.append((token, 'MED'))\n",
    "    else:\n",
    "        word_embedding_tags.append((token, 'UNTAGGED'))\n",
    "        not_tagged += 1\n",
    "\n",
    "not_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(word_embedding_tags, columns=['word', 'tag'])\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "fig, (axis1) = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.countplot(y=\"tag\", data=dataframe, color='dodgerblue', order=dataframe['tag'].value_counts().index)\n",
    "\n",
    "axis1.set_xlabel(\"Nº de tokens\", fontsize=20, weight='bold')\n",
    "axis1.set_ylabel(\"Tag\", fontsize=20, weight='bold')\n",
    "plt.grid(False)\n",
    "plt.xscale('log')\n",
    "\n",
    "total = len(dataframe)\n",
    "for p in axis1.patches:\n",
    "    width = p.get_width()\n",
    "    axis1.text(width, p.get_y()+0.5, '%.2f%%'%(100*float(width)/total), fontsize=15)\n",
    "\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tag_embedding = []\n",
    "\n",
    "for token, tag in word_tags:\n",
    "    if token in words_set:\n",
    "        word_tag_embedding.append((token, tag, 'Sim'))\n",
    "    else:\n",
    "        word_tag_embedding.append((token, tag, 'Não'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(word_tag_embedding, columns=['word', 'tag', 'word embedding'])\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "fig, (axis1) = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.countplot(y=\"tag\", data=dataframe, hue='word embedding', order=dataframe['tag'].value_counts().index)\n",
    "\n",
    "axis1.set_xlabel(\"Nº de tokens\", fontsize=20, weight='bold')\n",
    "axis1.set_ylabel(\"Tag\", fontsize=20, weight='bold')\n",
    "plt.grid(False)\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='lower right', title='word embedding', fontsize='x-large', title_fontsize='x-large')\n",
    "\n",
    "total = len(dataframe)\n",
    "for p in axis1.patches:\n",
    "    width = p.get_width()\n",
    "    axis1.text(width, p.get_y()+0.35, '%.2f%%'%(100*float(width)/total), fontsize=15)\n",
    "\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for doc in items_words:\n",
    "    for tok in doc:\n",
    "        if tok in words_set:\n",
    "            count += 1\n",
    "            \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sub = 0\n",
    "num_verb = 0\n",
    "num_adj = 0\n",
    "num_med = 0\n",
    "\n",
    "for doc in items_words:\n",
    "    sub = False\n",
    "    verb = False\n",
    "    adj = False\n",
    "    med = False\n",
    "    for tok in doc:\n",
    "        if tok in word_class and word_class[tok] == 'N':\n",
    "            sub = True\n",
    "        elif tok in word_class and word_class[tok] == 'V':\n",
    "            verb = True\n",
    "        elif tok in word_class and word_class[tok] == 'A':\n",
    "            adj = True\n",
    "        elif tok in medicamentos:\n",
    "            med = True\n",
    "\n",
    "    if sub:\n",
    "        num_sub += 1\n",
    "    if verb:\n",
    "        num_verb += 1\n",
    "    if adj:\n",
    "        num_adj += 1\n",
    "    if med:\n",
    "        num_med += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_sub)\n",
    "print(num_verb)\n",
    "print(num_adj)\n",
    "print(num_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(items_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_untagged = []\n",
    "words_untagged_woembedding = []\n",
    "\n",
    "for word, tag in word_tags:\n",
    "    if tag == 'UNTAGGED' and word in words_set:\n",
    "        words_untagged.append(word)\n",
    "    elif tag == 'UNTAGGED':\n",
    "        words_untagged_woembedding.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words_untagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words_untagged_woembedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.sample(words_untagged, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.sample(words_untagged_woembedding, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
