{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import collections\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from nlp.preprocessing import (\n",
    "    clean_text,\n",
    "    preprocess,\n",
    "    tokenize,\n",
    "    preprocess_document,\n",
    "    tokenize_document,\n",
    "    get_stopwords, \n",
    "    lemmatization_document,\n",
    "    get_canonical_words,\n",
    "    spellcheck_document)\n",
    "from nlp.pos_tagging import (\n",
    "    get_tokens_tags\n",
    ")\n",
    "from nlp.utils import (\n",
    "    read_json_file,\n",
    "    plot_histogram,\n",
    "    get_completetext,\n",
    "    plot_wordcloud,\n",
    "    print_statistics,\n",
    "    groups_frequency_sort)\n",
    "from nlp.text_statistics import (\n",
    "    count_tokens,\n",
    "    unique_tokens\n",
    ")\n",
    "from nlp.grouping import (\n",
    "    get_groups,\n",
    "    get_groups_size,\n",
    "    get_unigram_groups,\n",
    "    get_two_tokens_groups,\n",
    "    get_first_token_groups,\n",
    "    get_bigram_groups,\n",
    "    get_first_two_groups,\n",
    "    groups_frequency_sort\n",
    ")\n",
    "from utils.read_files import (\n",
    "    get_items)\n",
    "from item.item_list import (\n",
    "    ItemList,\n",
    "    Item\n",
    ")\n",
    "from item.spellcheckeropt import SpellcheckerOpt\n",
    "from item.utils import get_tokens_set\n",
    "from textpp_ptbr.preprocessing import TextPreProcessing as tpp\n",
    "from gensim.parsing.preprocessing import (\n",
    "    strip_multiple_whitespaces,\n",
    "    strip_non_alphanum,\n",
    "    strip_punctuation2,\n",
    "    strip_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_licitacao(file_items, include_price=True, include_dsc_unidade=True,\n",
    "                          recurso_limit=5.0, area='Saúde'):\n",
    "\n",
    "    file_recurso = '../dados/licitacao_vlr_recurso_funcao.csv'\n",
    "    data_recurso = pd.read_csv(file_recurso, sep=';')\n",
    "    licitacoes = data_recurso.loc[(data_recurso['nom_funcao'] == area) & \\\n",
    "                                  (data_recurso['proporcao_vlr'] >= recurso_limit)]\n",
    "    seq_dim_licitacao_list = list(licitacoes['seq_dim_licitacao'])\n",
    "\n",
    "    data = pd.read_csv(file_items, sep=';')\n",
    "    data = data.loc[data['seq_dim_licitacao'].isin(seq_dim_licitacao_list)]\n",
    "\n",
    "    if include_price and include_dsc_unidade:\n",
    "        items = data[['nom_item', 'seq_dim_licitacao', 'vlr_unitario_homologado', 'dsc_unidade_medida']].values.tolist()\n",
    "    elif include_price:\n",
    "        items = data[['nom_item', 'vlr_unitario_homologado']].values.tolist()\n",
    "    else:\n",
    "        items = list(data['nom_item'])\n",
    "\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../dados/itens_pregao_pitem_saude.csv'\n",
    "items = get_items_licitacao(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1530592"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['COLAGENASE 0,6UI/G', 1191385, 8.97, 'UNIDADE'],\n",
       " ['CAMPO OPERATÓRIO 45CMX50CM', 1007594, 161.77, 'PCT'],\n",
       " ['KIT PET', 1162895, 71.42, 'UNIDADE'],\n",
       " ['TINTA RELEVO PARA TECIDO BRAN.', 1043060, 24.45, 'CAIXA'],\n",
       " ['Termômetro clínico digital portátil para medir temperatura, com leitura digital em escala Celsius.',\n",
       "  1021726,\n",
       "  10.9,\n",
       "  'UNIDADE'],\n",
       " ['Diclofenaco de Sodio - 75mg /3ml', 1181254, 0.503, 'AMPOLA'],\n",
       " ['017308 PANFLETO INFORMATIVO PARA DIVUGACAO DE E', 1134250, 0.34, 'UNIDADE'],\n",
       " ['Bota de segurança, cano curto, tipo ipermeavedl, de uso proficional, confeccionada em policloreto de vinila (pvc) injetado em uma so peça. Cano Longo:325 mmn  39. Solado Desenho anti-derrapante, de facil limpeza/higienização.',\n",
       "  999848,\n",
       "  34.5,\n",
       "  'Caixa 1 Par'],\n",
       " ['CIPROFLOXACINO, 500 MG', 1186010, 0.17, 'comprimido'],\n",
       " ['Serviço de Recapagem de Pneus Misto 1100 x 22', 1012681, 670.0, 'Unidade']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_word = read_json_file('../dados/palavras/right_words_nilc.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_descriptions = []\n",
    "stopwords_ = get_stopwords()\n",
    "relevant_stopwords = {'para', 'com', 'nao', 'mais', 'muito', 'so', 'sem', 'mesmo', 'mesma', 'ha', 'haja', 'hajam', 'houver', 'houvera', 'seja', 'sejam', 'fosse', 'fossem', 'forem', 'sera', 'serao', 'seria', 'seriam', 'tem', 'tinha', 'teve', 'tinham', 'tenha', 'tiver', 'tiverem', 'tera', 'terao', 'teria', 'teriam', 'uma', 'mais', 'entre'}\n",
    "stopwords_ = stopwords_ - relevant_stopwords\n",
    "canonical_form, word_class = get_canonical_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'ao',\n",
       " 'aos',\n",
       " 'aquela',\n",
       " 'aquelas',\n",
       " 'aquele',\n",
       " 'aqueles',\n",
       " 'aquilo',\n",
       " 'as',\n",
       " 'ate',\n",
       " 'até',\n",
       " 'como',\n",
       " 'da',\n",
       " 'das',\n",
       " 'de',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'dele',\n",
       " 'deles',\n",
       " 'depois',\n",
       " 'do',\n",
       " 'dos',\n",
       " 'e',\n",
       " 'ela',\n",
       " 'elas',\n",
       " 'ele',\n",
       " 'eles',\n",
       " 'em',\n",
       " 'era',\n",
       " 'eram',\n",
       " 'eramos',\n",
       " 'essa',\n",
       " 'essas',\n",
       " 'esse',\n",
       " 'esses',\n",
       " 'esta',\n",
       " 'estamos',\n",
       " 'estao',\n",
       " 'estas',\n",
       " 'estava',\n",
       " 'estavam',\n",
       " 'estavamos',\n",
       " 'este',\n",
       " 'esteja',\n",
       " 'estejam',\n",
       " 'estejamos',\n",
       " 'estes',\n",
       " 'esteve',\n",
       " 'estive',\n",
       " 'estivemos',\n",
       " 'estiver',\n",
       " 'estivera',\n",
       " 'estiveram',\n",
       " 'estiveramos',\n",
       " 'estiverem',\n",
       " 'estivermos',\n",
       " 'estivesse',\n",
       " 'estivessem',\n",
       " 'estivessemos',\n",
       " 'estivéramos',\n",
       " 'estivéssemos',\n",
       " 'estou',\n",
       " 'está',\n",
       " 'estávamos',\n",
       " 'estão',\n",
       " 'eu',\n",
       " 'foi',\n",
       " 'fomos',\n",
       " 'for',\n",
       " 'fora',\n",
       " 'foram',\n",
       " 'foramos',\n",
       " 'formos',\n",
       " 'fossemos',\n",
       " 'fui',\n",
       " 'fôramos',\n",
       " 'fôssemos',\n",
       " 'hajamos',\n",
       " 'hao',\n",
       " 'havemos',\n",
       " 'hei',\n",
       " 'houve',\n",
       " 'houvemos',\n",
       " 'houveram',\n",
       " 'houveramos',\n",
       " 'houverao',\n",
       " 'houverei',\n",
       " 'houverem',\n",
       " 'houveremos',\n",
       " 'houveria',\n",
       " 'houveriam',\n",
       " 'houveriamos',\n",
       " 'houvermos',\n",
       " 'houverá',\n",
       " 'houverão',\n",
       " 'houveríamos',\n",
       " 'houvesse',\n",
       " 'houvessem',\n",
       " 'houvessemos',\n",
       " 'houvéramos',\n",
       " 'houvéssemos',\n",
       " 'há',\n",
       " 'hão',\n",
       " 'isso',\n",
       " 'isto',\n",
       " 'ja',\n",
       " 'já',\n",
       " 'lhe',\n",
       " 'lhes',\n",
       " 'mas',\n",
       " 'me',\n",
       " 'meu',\n",
       " 'meus',\n",
       " 'minha',\n",
       " 'minhas',\n",
       " 'na',\n",
       " 'nas',\n",
       " 'nem',\n",
       " 'no',\n",
       " 'nos',\n",
       " 'nossa',\n",
       " 'nossas',\n",
       " 'nosso',\n",
       " 'nossos',\n",
       " 'num',\n",
       " 'numa',\n",
       " 'não',\n",
       " 'nós',\n",
       " 'o',\n",
       " 'os',\n",
       " 'ou',\n",
       " 'pela',\n",
       " 'pelas',\n",
       " 'pelo',\n",
       " 'pelos',\n",
       " 'por',\n",
       " 'qual',\n",
       " 'quando',\n",
       " 'que',\n",
       " 'quem',\n",
       " 'sao',\n",
       " 'se',\n",
       " 'sejamos',\n",
       " 'serei',\n",
       " 'seremos',\n",
       " 'seriamos',\n",
       " 'será',\n",
       " 'serão',\n",
       " 'seríamos',\n",
       " 'seu',\n",
       " 'seus',\n",
       " 'somos',\n",
       " 'sou',\n",
       " 'sua',\n",
       " 'suas',\n",
       " 'são',\n",
       " 'só',\n",
       " 'tambem',\n",
       " 'também',\n",
       " 'te',\n",
       " 'temos',\n",
       " 'tenham',\n",
       " 'tenhamos',\n",
       " 'tenho',\n",
       " 'terei',\n",
       " 'teremos',\n",
       " 'teriamos',\n",
       " 'terá',\n",
       " 'terão',\n",
       " 'teríamos',\n",
       " 'teu',\n",
       " 'teus',\n",
       " 'tinhamos',\n",
       " 'tive',\n",
       " 'tivemos',\n",
       " 'tivera',\n",
       " 'tiveram',\n",
       " 'tiveramos',\n",
       " 'tivermos',\n",
       " 'tivesse',\n",
       " 'tivessem',\n",
       " 'tivessemos',\n",
       " 'tivéramos',\n",
       " 'tivéssemos',\n",
       " 'tu',\n",
       " 'tua',\n",
       " 'tuas',\n",
       " 'tém',\n",
       " 'tínhamos',\n",
       " 'um',\n",
       " 'voce',\n",
       " 'voces',\n",
       " 'você',\n",
       " 'vocês',\n",
       " 'vos',\n",
       " 'à',\n",
       " 'às',\n",
       " 'é',\n",
       " 'éramos'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing items descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in items:\n",
    "    description = item[0]\n",
    "    licitacao = item[1]\n",
    "    price = item[2]\n",
    "    dsc_unidade = item[3]\n",
    "    if type(dsc_unidade) == str:\n",
    "        dsc_unidade = tpp.remove_accents(dsc_unidade.lower())\n",
    "    elif math.isnan(dsc_unidade):\n",
    "        dsc_unidade = \"\"\n",
    "    doc = preprocess_document(description, remove_numbers=False, stopwords=stopwords_)\n",
    "    doc = tokenize_document(doc)\n",
    "    doc = spellcheck_document(doc, right_word)\n",
    "    doc = lemmatization_document(doc, canonical_form)\n",
    "    items_descriptions.append((doc, licitacao, price, dsc_unidade, description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1530592"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(items_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_preprocessed = []\n",
    "\n",
    "for doc in items_descriptions:\n",
    "    flag = False\n",
    "    for tok in doc[0]:\n",
    "        if 'servico' in tok or 'prestacao' in tok or 'servicos' in tok or 'prestacoes' in tok:\n",
    "            flag = True\n",
    "            break\n",
    "    if 'servico' in doc[3] or 'prestacao' in doc[3] or 'servicos' in doc[3] or 'prestacoes' in doc[3]:\n",
    "        flag = True\n",
    "    if flag == False:\n",
    "        items_preprocessed.append(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_preprocessed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(items_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dados/items_preprocessed.json\", \"w\") as jfile:\n",
    "    json.dump(items_preprocessed, jfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "licitacao_items = collections.defaultdict(list)\n",
    "\n",
    "for d in items_descriptions:\n",
    "    licitacao_items[d[1]].append(d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(licitacao_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dados/licitacao_items_preprocessed.json\", \"w\") as jfile:\n",
    "    json.dump(licitacao_items, jfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_descriptions[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemlist = ItemList()\n",
    "itemlist.load_items_from_list(items_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemlist.save_items('../dados/items_preprocessed_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemlist = ItemList()\n",
    "itemlist.load_items_from_file('../dados/items_preprocessed_v3.zip', original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1530512"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itemlist.items_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "servicos = ItemList()\n",
    "newitems = ItemList()\n",
    "\n",
    "for item in itemlist.items_list:\n",
    "    item_dict = item.get_item_dict()\n",
    "    flag = False\n",
    "    for tok in item_dict['palavras']:\n",
    "        if 'servico' in tok or 'prestacao' in tok or 'servicos' in tok or 'prestacoes' in tok:\n",
    "            flag = True\n",
    "            break\n",
    "    if 'servico' in item_dict['dsc_unidade_medida'] or 'prestacao' in item_dict['dsc_unidade_medida'] or \\\n",
    "       'servicos' in item_dict['dsc_unidade_medida'] or 'prestacoes' in item_dict['dsc_unidade_medida']:\n",
    "        flag = True\n",
    "    if flag:\n",
    "        servicos.items_list.append(item)\n",
    "    else:\n",
    "        newitems.items_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40708"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(servicos.items_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1489804"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newitems.items_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "servicos.save_items('../dados/items_preprocessed_v3_servicos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "newitems.save_items('../dados/items_preprocessed_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'palavras': ['colagenase'], 'unidades_medida': ['ui'], 'números': ['0', '6'], 'cores': [], 'materiais': [], 'tamanho': [], 'quantidade': [], 'preço': 8.97, 'dsc_unidade_medida': 'unidade', 'original': 'COLAGENASE 0,6UI/G', 'licitação': 1191385, 'original_prep': ['colagenase', '0', '6', 'ui', 'g']}\n"
     ]
    }
   ],
   "source": [
    "newitems.items_list[0].print_item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train-test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemlist = ItemList()\n",
    "itemlist.load_items_from_file('../dados/items_preprocessed_v3.zip', original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1489804"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itemlist.items_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "licitacoes_set = set()\n",
    "\n",
    "for item in itemlist.items_list:\n",
    "    item_dict = item.get_item_dict()\n",
    "    licitacoes_set.add(item_dict['licitação'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(999)\n",
    "train_set = set(random.sample(list(licitacoes_set), int(0.8*len(licitacoes_set))))\n",
    "test_set = licitacoes_set - train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24466\n",
      "6117\n",
      "30583\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(len(licitacoes_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ItemList()\n",
    "test = ItemList()\n",
    "\n",
    "for item in itemlist.items_list:\n",
    "    item_dict = item.get_item_dict()\n",
    "    if item_dict['licitação'] in train_set:\n",
    "        train.items_list.append(item)\n",
    "    else:\n",
    "        test.items_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1195143"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.items_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294661"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.items_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.save_items('../dados/items_preprocessed_v3_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.save_items('../dados/items_preprocessed_v3_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
